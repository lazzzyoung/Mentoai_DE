import requests
import time
import random
import logging

logger = logging.getLogger(__name__)

# ë¦¬ìŠ¤íŠ¸ APIë¥¼ ìˆœíšŒ, ê³µê³  ID ëª©ë¡ ìˆ˜ì§‘ í•¨ìˆ˜
def fetch_job_id_list(session, base_url, group_id, job_id, limit=100):
    
    job_ids = []
    offset = 0
    api_url = f"{base_url}/api/chaos/navigation/v1/results"
    
    logger.info(f"ID ìˆ˜ì§‘ ì‹œì‘ (Group: {group_id}, Job: {job_id})")

    while True:
        try:
            params = {
                "job_group_id": group_id,
                "job_ids": job_id,
                "country": "kr",
                "job_sort": "job.popularity_order",
                "years": "-1",
                "locations": "all",
                "limit": "20",
                "offset": offset
            }
            
            # session ì‚¬ìš©í•˜ì—¬ ì—°ê²° ì¬ì‚¬ìš©
            response = session.get(api_url, params=params, timeout=10)
            
            if response.status_code != 200:
                logger.error(f"âš ï¸ ë¦¬ìŠ¤íŠ¸ ìš”ì²­ ì‹¤íŒ¨ Code: {response.status_code}")
                break
                
            data_json = response.json()
            jobs = data_json.get('data', [])
            links = data_json.get('links', {})
            
            if not jobs:
                logger.info("ë” ì´ìƒ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break
                
            # ID ì¶”ì¶œ
            current_ids = [job['id'] for job in jobs]
            job_ids.extend(current_ids)
            
            logger.info(f"   + {len(current_ids)}ê°œ ìˆ˜ì§‘ (í˜„ì¬ ëˆ„ì : {len(job_ids)}ê°œ)")

            # ë‹¤ìŒ í˜ì´ì§€ í™•ì¸
            if not links.get('next'):
                break
            
            offset += 20
            
            # ì•ˆì „ì¥ì¹˜: ë„ˆë¬´ ë§ì´ ê¸ìœ¼ë©´ ì¤‘ë‹¨ (í…ŒìŠ¤íŠ¸ìš©)
            # if len(job_ids) >= limit:
            #     logger.info(f"ğŸ›‘ ì„¤ì •ëœ ì œí•œ({limit})ì— ë„ë‹¬í•˜ì—¬ ID ìˆ˜ì§‘ ì¤‘ë‹¨")
            #     break
            
            # ë´‡ íƒì§€ íšŒí”¼ìš©
            time.sleep(random.uniform(0.5, 1.0))

        except requests.exceptions.Timeout:
            logger.error("âš ï¸ ë¦¬ìŠ¤íŠ¸ ìš”ì²­ íƒ€ì„ì•„ì›ƒ. ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„ í•„ìš”.")
            time.sleep(2)
            break
        except Exception as e:
            logger.error(f"âš ï¸ ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì—ëŸ¬: {e}")
            break
            
    return job_ids

#ìƒì„¸ API í˜¸ì¶œ í›„ Raw Json ë°˜í™˜
def fetch_job_detail_raw(session, base_url, job_id):
   
    #Request URLì— í˜„ì¬ ì‹œê°„ì„ íŒŒë¼ë¯¸í„°ë¡œ ë„£ì–´ ì „ì†¡í•˜ê¸°ìœ„í•´ ì‘ì„±
    timestamp = int(time.time() * 1000)
    target_url = f"{base_url}/api/chaos/jobs/v4/{job_id}/details?{timestamp}="
    
    try:
        response = session.get(target_url, timeout=10)
        
        if response.status_code == 200:
            return response.json().get('data', {}).get('job', {})
        elif response.status_code == 404:
            logger.warning(f"âš ï¸ ê³µê³  ì‚­ì œë¨ ë˜ëŠ” ë¹„ê³µê°œ (ID: {job_id})")
            return None
        else:
            logger.warning(f"âš ï¸ ìƒì„¸ ìš”ì²­ ì‹¤íŒ¨ Code: {response.status_code} (ID: {job_id})")
            return None

    except requests.exceptions.Timeout:
        logger.error(f"âš ï¸ ìƒì„¸ ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ID: {job_id})")
        return None
    except Exception as e:
        logger.error(f"âš ï¸ ìƒì„¸ ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬ (ID: {job_id}): {e}")
        return None