import requests
from bs4 import BeautifulSoup
import re

def test_crawler_structure():
    print("ğŸš€ ì›Œí¬24 ë°ì´í„° êµ¬ì¡° ì •ë°€ ì§„ë‹¨ ì‹œì‘...")
    
    # 1. ìš”ì²­ ì„¤ì •
    url = "https://www.work24.go.kr/wk/a/b/1200/retriveDtlEmpSrchList.do?occupation=135101%7C135102%7C136102%7C026%7C024&pageIndex=1"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }

    try:
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # 2. ê³µê³  í–‰(Row) ì°¾ê¸°
        job_rows = soup.find_all('tr', id=re.compile(r'^list\d+'))
        print(f"ğŸ“Œ ë°œê²¬ëœ ê³µê³  í–‰(Row) ê°œìˆ˜: {len(job_rows)}ê°œ\n")

        # 3. ê° í–‰ì˜ td ë°ì´í„° ë‚ ê²ƒ ê·¸ëŒ€ë¡œ ì¶œë ¥
        for i, row in enumerate(job_rows):
            print(f"--- [ê³µê³  #{i+1}] ---")
            cols = row.select('td')
            print(f"ğŸ“Š ì¹¸(td) ê°œìˆ˜: {len(cols)}")
            
            for idx, col in enumerate(cols):
                # í…ìŠ¤íŠ¸ ë‚´ë¶€ì˜ ì§€ì €ë¶„í•œ ê³µë°±/ì¤„ë°”ê¿ˆì„ ì‹ë³„í•˜ê¸° ìœ„í•´ separator ì‚¬ìš©
                raw_text = col.get_text(separator='|', strip=True)
                print(f"  ğŸ”¹ td[{idx}]: {raw_text}")
            
            print("-" * 50)
            
            # ë„ˆë¬´ ë§ì´ ì¶œë ¥ë˜ë©´ ë³´ê¸° í˜ë“œë‹ˆ 3ê°œë§Œ ë³´ê³  ì¢…ë£Œ
            if i >= 2:
                print("... (ì´í•˜ ìƒëµ) ...")
                break

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")

if __name__ == "__main__":
    test_crawler_structure()