import requests
from bs4 import BeautifulSoup
import json
import re

def test_scraper_final():
    print("ğŸš€ ì›Œí¬24 ìµœì¢… í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ (URL ë° íšŒì‚¬ëª… ë³´ì™„)...")
    
    url = "https://www.work24.go.kr/wk/a/b/1200/retriveDtlEmpSrchList.do?occupation=135101%7C135102%7C136102%7C026%7C024&pageIndex=1"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }

    try:
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # IDê°€ listë¡œ ì‹œì‘í•˜ëŠ” í–‰ ìˆ˜ì§‘
        job_rows = soup.find_all('tr', id=re.compile(r'^list\d+'))
        print(f"ğŸ“Œ ë°œê²¬ëœ ê³µê³  í–‰(Row) ê°œìˆ˜: {len(job_rows)}ê°œ\n")

        results = []
        for row in job_rows:
            # 1. íšŒì‚¬ëª…: 'corp'ê°€ ë“¤ì–´ê°„ span ë˜ëŠ” td ì•ˆì˜ í…ìŠ¤íŠ¸
            corp_tag = row.select_one('.corp_name') or row.select_one('td.left')
            company = corp_tag.get_text(strip=True).split('ìš”ì•½ë³´ê¸°')[0] if corp_tag else "N/A"
            
            # 2. ê³µê³ ëª… ë° ìƒì„¸ URL ìƒì„±
            title = "N/A"
            full_link = "N/A"
            
            all_links = row.find_all('a')
            for a in all_links:
                href = a.get('href', '')
                # ì¸ì¦ë²ˆí˜¸(K...) ì¶”ì¶œ
                auth_match = re.search(r"(K\d+)", href)
                if auth_match:
                    auth_no = auth_match.group(1)
                    title = a.get_text(strip=True)
                    # âœ… ì‚¬ìš©ìë‹˜ì´ í™•ì¸í•˜ì‹  'ì§„ì§œ' ìƒì„¸ í˜ì´ì§€ ê²½ë¡œë¡œ ì¡°ë¦½
                    full_link = (
                        f"https://www.work24.go.kr/wk/a/b/1500/empDetailAuthView.do?"
                        f"wantedAuthNo={auth_no}&infoTypeCd=VALIDATION&infoTypeGroup=tb_workinfoworknet"
                    )
                    break

            if title != "N/A":
                results.append({
                    "company": company,
                    "title": title,
                    "link": full_link
                })

        print(json.dumps(results[:5], indent=2, ensure_ascii=False))

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")

if __name__ == "__main__":
    test_scraper_final()