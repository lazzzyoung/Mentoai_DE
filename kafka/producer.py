# kafka/producer.py
import time
import json
import re
import requests
from bs4 import BeautifulSoup
from kafka import KafkaProducer

def get_kafka_producer():
    return KafkaProducer(
        bootstrap_servers=['localhost:9092'],
        value_serializer=lambda v: json.dumps(v).encode('utf-8')
    )

def clean_space(text):
    if not text: return ""
    return re.sub(r'\s+', ' ', text).strip()

def scrape_and_produce(page_index=1):
    producer = get_kafka_producer()
    topic_name = 'career_raw'
    
    print(f"ğŸš€ [Page {page_index}] ê°•ë ¥ í¬ë¡¤ë§ ì‹œì‘ (Hidden Auth No íƒìƒ‰)...")
    
    url = f"https://www.work24.go.kr/wk/a/b/1200/retriveDtlEmpSrchList.do?occupation=135101%7C135102%7C136102%7C026%7C024&pageIndex={page_index}"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }

    try:
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        job_rows = soup.find_all('tr', id=re.compile(r'^list\d+'))
        
        count = 0
        for row in job_rows:
            cols = row.select('td')
            if len(cols) < 3: continue

            # -------------------------------------------------
            # 1. K-Number(êµ¬ì¸ì¸ì¦ë²ˆí˜¸) ì „ìˆ˜ ì¡°ì‚¬
            # -------------------------------------------------
            # hrefê°€ #noneì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, row ì „ì²´ HTMLì—ì„œ íŒ¨í„´ ê²€ìƒ‰
            # íŒ¨í„´: K + ìˆ«ì 10ìë¦¬ ì´ìƒ (ì˜ˆ: K120422601150021)
            row_html = str(row)
            auth_match = re.search(r"(K\d{10,})", row_html)
            
            auth_no = "N/A"
            full_link = "N/A"
            
            if auth_match:
                auth_no = auth_match.group(1)
                full_link = (
                    f"https://www.work24.go.kr/wk/a/b/1500/empDetailAuthView.do?"
                    f"wantedAuthNo={auth_no}&infoTypeCd=VALIDATION&infoTypeGroup=tb_workinfoworknet"
                )
            else:
                # Kë²ˆí˜¸ë¥¼ ëª» ì°¾ìœ¼ë©´ ì˜ë¯¸ ì—†ëŠ” ë°ì´í„°ì´ë¯€ë¡œ ìŠ¤í‚µ
                continue

            # -------------------------------------------------
            # 2. íšŒì‚¬ëª… & ì œëª© (íŒŒì´í”„ ë¶„ë¦¬ ë°©ì‹)
            # -------------------------------------------------
            td0_parts = cols[0].get_text(separator='|', strip=True).split('|')
            company = td0_parts[0].strip() if len(td0_parts) > 0 else "N/A"
            
            # ì œëª© ì¶”ì¶œ ë¡œì§ ë³´ì™„: 'ìš”ì•½ë³´ê¸°' ë“±ì´ ì•„ë‹Œ ì§„ì§œ ì œëª© ì°¾ê¸°
            title = "N/A"
            if len(td0_parts) > 1:
                potential_title = td0_parts[1].strip()
                # ë§Œì•½ ë‘ ë²ˆì§¸ ì¡°ê°ì´ ì´ìƒí•˜ë©´ ì„¸ ë²ˆì§¸ ì¡°ê° í™•ì¸
                if "ì…ì‚¬ì§€ì›" in potential_title or "ìš”ì•½ë³´ê¸°" in potential_title:
                     if len(td0_parts) > 2:
                         title = td0_parts[2].strip()
                else:
                    title = potential_title

            # -------------------------------------------------
            # 3. ìƒì„¸ ì •ë³´ (ê¸‰ì—¬, ì§€ì—­ ë“±)
            # -------------------------------------------------
            td1_parts = cols[1].get_text(separator='|', strip=True).split('|')
            
            pay = "ë©´ì ‘ í›„ ê²°ì •"
            experience = "ê²½ë ¥ ë¬´ê´€"
            education = "í•™ë ¥ ë¬´ê´€"
            location = "ì§€ì—­ ë¯¸ìƒ"

            for part in td1_parts:
                part = clean_space(part)
                if not part: continue

                if any(x in part for x in ["ì—°ë´‰", "ì›”ê¸‰", "ì‹œê¸‰", "ë§Œì›", "ì›"]):
                    pay = part
                elif any(x in part for x in ["ê²½ë ¥", "ì‹ ì…"]):
                    experience = part
                elif any(x in part for x in ["í•™ë ¥", "ëŒ€ì¡¸", "ê³ ì¡¸", "ë°•ì‚¬"]):
                    education = part
                elif any(x in part for x in ["ì‹œ ", "êµ¬ ", "êµ° ", "ë¡œ ", "ê¸¸ "]) and "ì£¼" not in part:
                    location = part

            # -------------------------------------------------
            # 4. ë‚ ì§œ ì •ë³´
            # -------------------------------------------------
            td2_text = cols[2].get_text(separator='|', strip=True)
            deadline_match = re.search(r"ë§ˆê°ì¼\s?:\s?(\d{4}-\d{2}-\d{2})", td2_text)
            reg_match = re.search(r"ë“±ë¡ì¼\s?:\s?(\d{4}-\d{2}-\d{2})", td2_text)
            
            deadline = deadline_match.group(1) if deadline_match else "ì±„ìš©ì‹œê¹Œì§€"
            reg_date = reg_match.group(1) if reg_match else time.strftime('%Y-%m-%d')

            # -------------------------------------------------
            # 5. Kafka ì „ì†¡
            # -------------------------------------------------
            if title != "N/A" and full_link != "N/A":
                data = {
                    "source_id": auth_no,
                    "company": company,
                    "title": title,
                    "link": full_link,
                    "pay": pay,
                    "education": education,
                    "experience": experience,
                    "location": location,
                    "deadline": deadline,
                    "reg_date": reg_date,
                    "collected_at": time.strftime('%Y-%m-%dT%H:%M:%SZ')
                }
                
                producer.send(topic_name, value=data)
                print(f"âœ… [{company}] {title[:20]}...")
                count += 1
                
        producer.flush()
        print(f"\nğŸ‰ ì´ {count}ê±´ì˜ ë°ì´í„°ë¥¼ '{topic_name}' í† í”½ìœ¼ë¡œ ì „ì†¡í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
    finally:
        producer.close()

if __name__ == "__main__":
    scrape_and_produce(page_index=1)