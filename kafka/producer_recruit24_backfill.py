import sys
import os

# ê²½ë¡œ ì„¤ì • (utils íŒ¨í‚¤ì§€ ì¸ì‹ìš©)
sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))

import json
import time
import re
import random
from kafka import KafkaProducer
from kafka.utils.recruit24_scraper import fetch_job_list, get_detail_info, clean_space

def run_backfill(start_page, end_page):
    
    bootstrap_server = os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'localhost:9092')
    
    producer = KafkaProducer(
        bootstrap_servers=[bootstrap_server],
        value_serializer=lambda v: json.dumps(v).encode('utf-8'),
        linger_ms=20,
        batch_size=16384
    )
    
    TOPIC_NAME = 'career_backfill'

    print(f"ğŸ“‚ [Backfill] ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {start_page} ~ {end_page}í˜ì´ì§€ (Server: {bootstrap_server})")
    print(f"   ğŸ‘‰ Target Topic: {TOPIC_NAME}")

    total_count = 0
    
    for page in range(start_page, end_page + 1):
        print(f"\nğŸ“– [Page {page}/{end_page}] ë°ì´í„° ê¸ì–´ì˜¤ëŠ” ì¤‘...")
        job_rows = fetch_job_list(page_index=page)
        
        if not job_rows:
            print(f"   âš ï¸ {page}í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨ ë˜ëŠ” ê³µê³  ì—†ìŒ. Skip.")
            time.sleep(2)
            continue

        page_count = 0
        for i, row in enumerate(job_rows):
            try:
                row_html = str(row)
                
                auth_match = re.search(r"wantedAuthNo=([a-zA-Z0-9]+)", row_html)
                if auth_match:
                    auth_no = auth_match.group(1)
                else:
                    k_match = re.search(r"(K\d{10,})", row_html)
                    auth_no = k_match.group(1) if k_match else None
                
                if not auth_no: continue

                cols = row.select('td')
                if len(cols) < 3: continue
                
                td0_parts = cols[0].get_text(separator='|', strip=True).split('|')
                company = td0_parts[0].strip() if len(td0_parts) > 0 else "N/A"
                title = "N/A"
                if len(td0_parts) > 1:
                    potential_title = td0_parts[1].strip()
                    if "ì…ì‚¬ì§€ì›" in potential_title or "ìš”ì•½ë³´ê¸°" in potential_title:
                         if len(td0_parts) > 2: title = td0_parts[2].strip()
                    else:
                        title = potential_title

                td1_parts = cols[1].get_text(separator='|', strip=True).split('|')
                pay, location = "ë©´ì ‘ í›„ ê²°ì •", "ì§€ì—­ ë¯¸ìƒ"
                for part in td1_parts:
                    part = clean_space(part)
                    if any(x in part for x in ["ì—°ë´‰", "ì›”ê¸‰", "ì‹œê¸‰"]): pay = part
                    elif any(x in part for x in ["ì‹œ ", "êµ¬ ", "êµ° "]) and "ì£¼" not in part: location = part

                td2_text = cols[2].get_text(separator='|', strip=True)
                reg_match = re.search(r"ë“±ë¡ì¼\s?:\s?(\d{4}-\d{2}-\d{2})", td2_text)
                reg_date = reg_match.group(1) if reg_match else time.strftime('%Y-%m-%d')
                deadline_match = re.search(r"ë§ˆê°ì¼\s?:\s?(\d{4}-\d{2}-\d{2})", td2_text)
                deadline = deadline_match.group(1) if deadline_match else "ì±„ìš©ì‹œê¹Œì§€"

                detail = get_detail_info(auth_no)
                if not detail:
                     detail = {"job_description": "ìˆ˜ì§‘ ì—ëŸ¬", "requirements": "", "preferred": ""}

                worknet_link = f"https://www.work.go.kr/empInfo/empInfoSrch/detail/empDetailAuthView.do?wantedAuthNo={auth_no}"

                data = {
                    "source_id": auth_no,
                    "company": company,
                    "title": title,
                    "link": worknet_link,
                    "pay": pay,
                    "location": location,
                    "deadline": deadline,
                    "reg_date": reg_date,
                    "description": detail["job_description"],
                    "requirements": detail["requirements"],
                    "preferred_qualifications": detail["preferred"],
                    "collected_at": time.strftime('%Y-%m-%dT%H:%M:%SZ')
                }

                producer.send(
                    TOPIC_NAME, 
                    key=auth_no.encode('utf-8'),
                    value=data
                )
                
                if (i+1) % 10 == 0:
                    print(f"   âœ… [P.{page}] {i+1}ë²ˆì§¸: {company[:6]}... ì „ì†¡ ì™„ë£Œ")
                
                page_count += 1
                total_count += 1

            except Exception:
                continue
        
        producer.flush()
        print(f"   ğŸ [Page {page}] {page_count}ê±´ ì „ì†¡ ì™„ë£Œ. ëŒ€ê¸° ì¤‘...")
        time.sleep(random.uniform(2.0, 4.0)) 

    producer.close()
    print(f"\nğŸ‰ Backfill ì™„ë£Œ! ì´ {total_count}ê±´ì„ '{TOPIC_NAME}' í† í”½ìœ¼ë¡œ ì „ì†¡í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    s_page = int(sys.argv[1]) if len(sys.argv) > 1 else 1
    e_page = int(sys.argv[2]) if len(sys.argv) > 2 else 2
    run_backfill(s_page, e_page)