# MentoAI: Personalized AI Career Roadmap Service

**MentoAI**ëŠ” ì‚¬ìš©ìžì˜ ê¸°ìˆ  ìŠ¤íŽ™ê³¼ í¬ë§ ì§ë¬´ë¥¼ ë¶„ì„í•˜ì—¬, ìµœì‹  ì±„ìš© ê³µê³  ê¸°ë°˜ì˜ ë§žì¶¤í˜• ì»¤ë¦¬ì–´ ì„±ìž¥ ë¡œë“œë§µì„ ì œê³µí•˜ëŠ” AI ì„œë¹„ìŠ¤ìž…ë‹ˆë‹¤. 
ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ íŒŒì´í”„ë¼ì¸(Kafka, Spark, Airflow)ê³¼ RAG(Retrieval-Augmented Generation) ê¸°ìˆ ì„ ê²°í•©í•˜ì—¬, ë‹¨ìˆœí•œ ê³µê³  ì¶”ì²œì„ ë„˜ì–´ êµ¬ì²´ì ì¸ í•™ìŠµ ì „ëžµê³¼ ì•¡ì…˜ í”Œëžœì„ ì œì‹œí•©ë‹ˆë‹¤.

## ðŸ—ï¸ System Architecture

ë°ì´í„°ì˜ ìˆ˜ì§‘ë¶€í„° ì„œë¹„ìŠ¤ ì œê³µê¹Œì§€ì˜ ì „ì²´ ë°ì´í„° íë¦„ë„ìž…ë‹ˆë‹¤.

[Data Ingestion Layer]             [Data Processing Layer]
+-----------------+               +--------------------------+
|  Job Sites      |   Crawling    |  Apache Spark (ETL)      |
| (Wanted, etc.)  | ------------> |                          |
+-----------------+               | 1. Ingest (Kafka->S3)    |-----> [AWS S3 (Bronze)]
         |                        | 2. Process (Clean Data)  |-----> [PostgreSQL (Silver)]
         v                        | 3. Upsert (Embedding)    |-----> [Qdrant (Gold)]
+-----------------+               +--------------------------+
|  Apache Kafka   |                            ^
| (career_raw)    |                            |
+-----------------+                 (Trigger / Schedule)
         |                                     |
         +---------------------------> +----------------+
                                       | Apache Airflow |
                                       +----------------+

[Service & AI Layer]
+--------+       +------------------+       +------------------+
|        | <---> |  FastAPI Server  | <---> |    Qdrant DB     |
|  User  |       |   (RAG Engine)   |       |  (Vector Search) |
|        |       +------------------+       +------------------+
+--------+                 ^
                           |
                 +------------------+
                 |   Google Gemini  |
                 |  (Reasoning/LLM) |
                 +------------------+


## ðŸš€ Key Features

1. **Automated Data Pipeline**
   - Apache Airflowì™€ Sparkë¥¼ í™œìš©í•˜ì—¬ ì±„ìš© ê³µê³  ë°ì´í„°ë¥¼ ìˆ˜ì§‘(Bronze), ì •ì œ(Silver), ë²¡í„°í™”(Gold)í•˜ëŠ” ETL íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.
   - ì´ˆê¸° Streaming ì•„í‚¤í…ì²˜ì—ì„œ ì•ˆì •ì ì¸ ë°ì´í„° ì ìž¬ë¥¼ ìœ„í•´ Batch ë°©ì‹ìœ¼ë¡œ ìµœì í™”ë˜ì—ˆìŠµë‹ˆë‹¤.

2. **Semantic Search (Vector Search)**
   - Qdrant ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì™€ **KoSimCSE** ìž„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬, ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­ì´ ì•„ë‹Œ ë¬¸ë§¥ ê¸°ë°˜ì˜ ì§ë¬´ ì í•©ì„± ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

3. **RAG Based Consulting**
   - **Google Gemini 3 Flash** ëª¨ë¸ì„ í™œìš©í•˜ì—¬, ê²€ìƒ‰ëœ ê³µê³ ì™€ ì‚¬ìš©ìž í”„ë¡œí•„ì„ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.
   - ë¶€ì¡±í•œ ì—­ëŸ‰ì— ëŒ€í•œ ì ìˆ˜í™”(Scoring) ë° êµ¬ì²´ì ì¸ í•™ìŠµ ë¡œë“œë§µ(Gap Analysis)ì„ ì œê³µí•©ë‹ˆë‹¤.

## ðŸ—ï¸ System Architecture (Medallion Architecture)

ë°ì´í„°ëŠ” Bronze, Silver, Gold ë‹¨ê³„ë¥¼ ê±°ì¹˜ë©° ì ì§„ì ìœ¼ë¡œ ê°€ê³µë˜ì–´ ì„œë¹„ìŠ¤ì— í™œìš©ë©ë‹ˆë‹¤.

1. **Ingestion (Kafka)**: `producer_wanted.py`ë¥¼ í†µí•´ ê³µê³  ìˆ˜ì§‘ í›„ `career_raw` í† í”½ìœ¼ë¡œ ì „ì†¡
2. **Bronze Layer (S3)**: ì›ë³¸ JSON ë°ì´í„°ë¥¼ Parquet í˜•ì‹ìœ¼ë¡œ ë³´ì¡´ (Data Lake)
3. **Silver Layer (PostgreSQL)**: Sparkë¥¼ ì´ìš©í•œ ë°ì´í„° ì •ì œ(HTML ì œê±°, ìŠ¤í‚¤ë§ˆ ê²€ì¦) ë° RDBMS ì ìž¬
4. **Gold Layer (Qdrant)**: KoSimCSE ëª¨ë¸ë¡œ ê³µê³  ë³¸ë¬¸ ìž„ë² ë”© í›„ ë²¡í„° DB ì¸ë±ì‹±
5. **Orchestration (Airflow)**: Docker-out-of-Docker êµ¬ì¡°ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ìŠ¤ì¼€ì¤„ë§
6. **Service Layer (FastAPI)**: ì‚¬ìš©ìž ìš”ì²­ ì²˜ë¦¬ ë° RAG(Retrieval-Augmented Generation) ìˆ˜í–‰

## ðŸ“‚ Project Structure

MENTOAI_DE/
â”œâ”€â”€ dags/                       # Airflow DAG
â”‚   â””â”€â”€ mentoai_pipeline.py     # [Main] Kafka -> Bronze -> Silver -> Gold í†µí•© íŒŒì´í”„ë¼ì¸
â”œâ”€â”€ kafka/                      # ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ producer_wanted.py      # [Main] ì‹¤ì‹œê°„ ê³µê³  ìˆ˜ì§‘ê¸°
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ wanted_scraper.py   # ì›í‹°ë“œ ê³µê³  í¬ë¡¤ë§ ë¡œì§
â”œâ”€â”€ spark/                      # ë°ì´í„° ì²˜ë¦¬ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ job_ingest_bronze.py    # Task 1: Kafka -> S3 (Parquet)
â”‚   â”œâ”€â”€ job_process_silver.py   # Task 2: S3 -> Postgres (Data Cleaning)
â”‚   â”œâ”€â”€ job_upsert_gold.py      # Task 3: Postgres -> Qdrant (Embedding)
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ spark_session.py    # Spark ì„¸ì…˜ ìƒì„± í—¬í¼
â”‚       â”œâ”€â”€ text_cleaner.py     # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ìœ í‹¸
â”‚       â””â”€â”€ writers.py          # DB/S3 ì ìž¬ í•¨ìˆ˜
â”œâ”€â”€ server/                     # Backend API & AI Engine
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â””â”€â”€ main.py             # FastAPI ì—”ë“œí¬ì¸íŠ¸ & RAG ë¡œì§ (LangChain)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ infra/                      # ì¸í”„ë¼ ì„¤ì • (Docker)
â”‚   â”œâ”€â”€ airflow/                # Airflow ë¹Œë“œ ì„¤ì •
â”‚   â”œâ”€â”€ spark/                  # Spark ë¹Œë“œ ì„¤ì •
â”‚   â””â”€â”€ docker-compose.yml      # ì „ì²´ ì„œë¹„ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
â”œâ”€â”€ .env                        # í™˜ê²½ ë³€ìˆ˜ (AWS Key, Gemini Key, DB Info)
â””â”€â”€ README.md                   # ë³¸ ë¬¸ì„œ

## ðŸ“¡ API Endpoints

### 1. ê¸°ì—… ëª©ë¡ ì¶”ì²œ
* **POST** `/api/v3/jobs/recommend/{user_id}`
* ì‚¬ìš©ìžì˜ í”„ë¡œí•„(ê¸°ìˆ , ê²½ë ¥)ê³¼ ê°€ìž¥ ìœ ì‚¬í•œ ê³µê³  5ê°œë¥¼ ì¶”ì²œí•˜ê³ , ì í•©ë„ ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

### 2. ìƒì„¸ ì»¤ë¦¬ì–´ ì»¨ì„¤íŒ…
* **POST** `/api/v3/jobs/{job_id}/analyze/{user_id}`
* íŠ¹ì • ê³µê³ ì— ëŒ€í•´ í•©ê²©ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ì „ëžµ(ë¶€ì¡±í•œ ì , ì•¡ì…˜ í”Œëžœ, ë©´ì ‘ íŒ)ì„ JSON í˜•íƒœë¡œ ì œê³µí•©ë‹ˆë‹¤.

## âš¡ Prerequisites

ì´ í”„ë¡œì íŠ¸ë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ìš”êµ¬ì‚¬í•­ìž…ë‹ˆë‹¤.

* Docker & Docker Compose
* Python 3.9+
* API Keys:
    * Google Gemini API Key
    * AWS Access Key (S3 ì ‘ê·¼ìš©)

---

## âš¡ Quick Start

### 1. í™˜ê²½ ì„¤ì • (Prerequisites)
í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  í•„ìš”í•œ API í‚¤ë¥¼ ìž…ë ¥í•©ë‹ˆë‹¤.
(GOOGLE_API_KEY, AWS_ACCESS_KEY_ID, POSTGRES_USER, QDRANT_HOST ë“±)

### 2. ì¸í”„ë¼ ë¹Œë“œ ë° ì‹¤í–‰
ê° ì„œë¹„ìŠ¤(Airflow, Spark, Server)ë¥¼ ê°œë³„ Dockerfileë¡œ ë¹Œë“œí•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤.

cd infra
docker compose up -d --build

### 3. ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
Airflow ì›¹ UIì— ì ‘ì†í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„ í™œì„±í™”í•©ë‹ˆë‹¤.
* **URL**: http://localhost:8081
* **Account**: admin / admin
* **Action**: `mentoai_pipeline` DAGë¥¼ Unpause(ON) í•˜ê³  Trigger ì‹¤í–‰

### 4. API ì„œë¹„ìŠ¤ ì‚¬ìš©
FastAPI Swagger UIë¥¼ í†µí•´ ì¶”ì²œ ë° ì»¨ì„¤íŒ… APIë¥¼ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
* **URL**: http://localhost:8000/docs

## ðŸš€ Installation & Execution Guide

### 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì— .env íŒŒì¼ì„ ìƒì„±í•˜ê³  ì•„ëž˜ ë‚´ìš©ì„ ì±„ì›Œì£¼ì„¸ìš”.

# .env ì˜ˆì‹œ
GOOGLE_API_KEY=your_gemini_key
AWS_ACCESS_KEY_ID=your_aws_key
AWS_SECRET_ACCESS_KEY=your_aws_secret
S3_BUCKET_NAME=mentoai-career-raw
DATABASE_URL=postgresql://airflow:airflow@postgres:5432/mentoai
QDRANT_HOST=mentoai-qdrant

### 2. ì¸í”„ë¼ ë¹Œë“œ ë° ì‹¤í–‰
infra ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ì—¬ ëª¨ë“  ì„œë¹„ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

cd infra
/ docker compose up -d --build

### 3. ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (User Data)
PostgreSQL ì»¨í…Œì´ë„ˆì— ì ‘ì†í•˜ì—¬ ì‚¬ìš©ìž í…Œì´ë¸”ì„ ìƒì„±í•˜ê³  í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìž…ë ¥í•©ë‹ˆë‹¤.

# Postgres ì ‘ì†
/ docker exec -it mentoai-postgres psql -U airflow -d mentoai

# í…Œì´ë¸” ìƒì„± SQL ì‹¤í–‰
/ CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

/ CREATE TABLE IF NOT EXISTS user_specs (
    spec_id SERIAL PRIMARY KEY,
    user_id INT REFERENCES users(id) ON DELETE CASCADE,
    desired_job VARCHAR(100),
    career_years INT DEFAULT 0,
    education VARCHAR(100),
    skills TEXT[],
    certificates TEXT[],
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ìž…ë ¥
/ INSERT INTO users (username, email) VALUES ('ê°•íƒœì˜', 'tang0923@khu.ac.kr');

/ INSERT INTO user_specs (user_id, desired_job, career_years, education, skills, certificates) 
VALUES (1, 'Data Engineer', 0, 'í•™ì‚¬', ARRAY['Python', 'Spark', 'Kafka', 'Airflow'], ARRAY['ì •ë³´ì²˜ë¦¬ê¸°ì‚¬', 'SQLD']);

# ìž…ë ¥ í›„ \q ë¡œ ì¢…ë£Œ

### 4. ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (Airflow)
1. ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8081 ì ‘ì†
2. ë¡œê·¸ì¸: admin / admin
3. mentoai_pipeline DAGë¥¼ ì°¾ì•„ì„œ ì™¼ìª½ì˜ Toggleì„ ONìœ¼ë¡œ ë³€ê²½
4. ìš°ì¸¡ì˜ 'Trigger DAG' ë²„íŠ¼ í´ë¦­
5. Graph Viewì—ì„œ Kafka -> Bronze -> Silver -> Gold ìž‘ì—…ì´ ëª¨ë‘ Successë¡œ ë³€í•˜ëŠ”ì§€ í™•ì¸

### 5. API í…ŒìŠ¤íŠ¸
íŒŒì´í”„ë¼ì¸ì´ ì™„ë£Œë˜ë©´ RAG ì„œë²„ê°€ ì¤€ë¹„ë©ë‹ˆë‹¤. http://localhost:8000/docs ì— ì ‘ì†í•˜ê±°ë‚˜ ì•„ëž˜ ëª…ë ¹ì–´ë¡œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”.

# 1. ê¸°ì—… ì¶”ì²œ ëª©ë¡ ì¡°íšŒ (V3)
/ curl -X 'POST' 'http://localhost:8000/api/v3/jobs/recommend/1' -H 'accept: application/json' -d ''

# 2. íŠ¹ì • ê¸°ì—… ìƒì„¸ ì»¨ì„¤íŒ… (job_idëŠ” ìœ„ ì‘ë‹µì—ì„œ í™•ì¸)
/ curl -X 'POST' 'http://localhost:8000/api/v3/jobs/{JOB_ID}/analyze/1' -H 'accept: application/json' -d ''

---

## ðŸ› ï¸ Tech Stack Details

**Infrastructure**
* Docker Compose: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤(Airflow, Spark, DB, Server) í†µí•© ê´€ë¦¬

**Data Engineering**
* Kafka: ì‹¤ì‹œê°„ ê³µê³  ë°ì´í„° ë²„í¼ë§
* Spark (PySpark): ëŒ€ìš©ëŸ‰ ë°ì´í„° ì „ì²˜ë¦¬ ë° ë²¡í„°í™” (Batch Processing)
* Airflow: ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì˜ì¡´ì„± ê´€ë¦¬ ë° ìŠ¤ì¼€ì¤„ë§

**Storage**
* PostgreSQL: ì •í˜• ë°ì´í„°(ì‚¬ìš©ìž ì •ë³´, ì •ì œëœ ê³µê³ ) ì €ìž¥
* Qdrant: ê³µê³  í…ìŠ¤íŠ¸ ìž„ë² ë”© ë²¡í„° ì €ìž¥ ë° ìœ ì‚¬ë„ ê²€ìƒ‰
* AWS S3: Raw Data(JSON/Parquet) ì˜êµ¬ ë³´ê´€ (Data Lake)

**AI & Backend**
* FastAPI: ë¹„ë™ê¸° API ì„œë²„
* LangChain: LLM í”„ë¡¬í”„íŠ¸ ì²´ì´ë‹ ë° Output Parsing
* Google Gemini 3 Flash: ì¶”ë¡  ë° ë¡œë“œë§µ ìƒì„±
* KoSimCSE: í•œêµ­ì–´ íŠ¹í™” ë¬¸ìž¥ ìž„ë² ë”© ëª¨ë¸

---

## âš ï¸ Troubleshooting (Project History)

### 1. Airflow RBAC ê¶Œí•œ ì˜¤ë¥˜ (Access Denied)
* **í˜„ìƒ**: DB ì´ˆê¸°í™” í›„ ì›¹ UI ì ‘ì† ì‹œ 'Admin' ì—­í• ì´ ì—†ì–´ ëŒ€ì‹œë³´ë“œ ì ‘ê·¼ ë¶ˆê°€.
* **ì›ì¸**: docker-compose downìœ¼ë¡œ ì¸í•œ DB íœ˜ë°œ ë° ìžë™ ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸ ìž¬ì‹¤í–‰ ì‹¤íŒ¨.
* **í•´ê²°**: ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ `airflow users create` ëª…ë ¹ì–´ë¡œ ê´€ë¦¬ìž ê³„ì • ìˆ˜ë™ ìƒì„± ë° ê¶Œí•œ ë¶€ì—¬.

### 2. PostgreSQL ë°ì´í„° íœ˜ë°œ ë° ë³¼ë¥¨ ì´ìŠˆ
* **í˜„ìƒ**: ì»¨í…Œì´ë„ˆë¥¼ ë‚´ë ¸ë‹¤ ì˜¬ë¦¬ë©´ DBì— ìƒì„±í•œ í…Œì´ë¸”ê³¼ ìœ ì € ë°ì´í„°ê°€ ì‚¬ë¼ì§.
* **ì›ì¸**: Docker ë³¼ë¥¨ ë§¤í•‘ ëˆ„ë½ìœ¼ë¡œ ë°ì´í„°ê°€ ì˜êµ¬ ì €ìž¥ë˜ì§€ ì•ŠìŒ.
* **í•´ê²°**: docker-compose.ymlì˜ postgres ì„œë¹„ìŠ¤ì— `./postgres_data:/var/lib/postgresql/data` ë§¤í•‘ ì¶”ê°€.

### 3. Spark Streaming ì ìž¬ ëˆ„ë½ (Fake Success)
* **í˜„ìƒ**: Airflow íƒœìŠ¤í¬ëŠ” ì„±ê³µìœ¼ë¡œ ëœ¨ì§€ë§Œ Postgresì— í…Œì´ë¸”ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ.
* **ì›ì¸**: `writeStream` ì‚¬ìš© ì‹œ `awaitTermination()` ì„¤ì • ë¶€ìž¬ë¡œ ì ìž¬ ì™„ë£Œ ì „ ì„¸ì…˜ ì¢…ë£Œ.
* **í•´ê²°**: ìœ ì‹¤ ë°ì´í„° ë³µêµ¬ë¥¼ ìœ„í•´ S3 ë°ì´í„°ë¥¼ ëª½ë•… ì½ì–´ ì²˜ë¦¬í•˜ëŠ” **Batch Recovery ëª¨ë“œ** ë„ìž… ë° í…Œì´ë¸” ê°•ì œ ìƒì„±.

### 4. Qdrant ë©”íƒ€ë°ì´í„° "ë¯¸ìƒ" ì¶œë ¥ ì´ìŠˆ
* **í˜„ìƒ**: ì¶”ì²œ ëª©ë¡ API ì‘ë‹µì—ì„œ ê¸°ì—…ëª…ê³¼ ê³µê³ ëª…ì´ "ë¯¸ìƒ"ìœ¼ë¡œ ë‚˜ì˜´.
* **ì›ì¸**: LangChainì˜ `vector_store`ê°€ Qdrantì˜ íŠ¹ì • íŽ˜ì´ë¡œë“œ í•„ë“œë¥¼ ì½ì–´ì˜¤ì§€ ëª»í•˜ëŠ” í˜¸í™˜ì„± ë¬¸ì œ.
* **í•´ê²°**: Qdrant Raw Clientë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ëœ IDë¡œ ì§ì ‘ í¬ì¸íŠ¸(Point)ë¥¼ ì¡°íšŒ(`retrieve`)í•˜ì—¬ íŽ˜ì´ë¡œë“œë¥¼ í™•ì‹¤í•˜ê²Œ ê°€ì ¸ì˜¤ë„ë¡ ë³´ì •.

### 5. Gemini JSON Parsing ì—ëŸ¬ (Output Parser)
* **í˜„ìƒ**: V3 ëª©ë¡ ì¡°íšŒ ì‹œ 500 Internal Server Error ë°œìƒ.
* **ì›ì¸**: `JsonOutputParser`ê°€ `List[JobSummary]` í˜•íƒœë¥¼ ì§ì ‘ ì²˜ë¦¬í•˜ì§€ ëª»í•¨.
* **í•´ê²°**: ë¦¬ìŠ¤íŠ¸ë¥¼ ê°ì‹¸ëŠ” ëž˜í¼ í´ëž˜ìŠ¤(`JobSummaryList`)ë¥¼ ì •ì˜í•˜ì—¬ íŒŒì„œì—ê²Œ ì „ë‹¬í•¨ìœ¼ë¡œì¨ ìŠ¤í‚¤ë§ˆ ì •í•©ì„± í™•ë³´.

### 6. QdrantClient ë²„ì „ í˜¸í™˜ì„± (search vs retrieve)
* **í˜„ìƒ**: `client.search()` í˜¸ì¶œ ì‹œ ì†ì„±ì´ ì—†ë‹¤ëŠ” ì—ëŸ¬ ë°œìƒ.
* **ì›ì¸**: ì„¤ì¹˜ëœ `qdrant-client` ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì´ ë‚®ì•„ ìµœì‹  ë©”ì„œë“œ ë¯¸ì§€ì›.
* **í•´ê²°**: ë²„ì „ ì˜ì¡´ì„±ì´ ì—†ëŠ” `vector_store.similarity_search`ë¡œ IDë¥¼ ë¨¼ì € ì°¾ê³ , êµ¬ë²„ì „ì—ì„œë„ ì§€ì›í•˜ëŠ” `client.retrieve`ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ ì ìš©.

### 7. ì±„ì  ì¸í”Œë ˆì´ì…˜ (Scoring Calibration)
* **í˜„ìƒ**: ì‚¬ìš©ìžì˜ ê²½ë ¥ì´ ë¶€ì¡±í•¨ì—ë„ ëª¨ë“  ê³µê³ ì— 90ì  ì´ìƒì˜ ë†’ì€ ì ìˆ˜ê°€ ë¶€ì—¬ë¨.
* **ì›ì¸**: í”„ë¡¬í”„íŠ¸ì˜ ì±„ì  ê¸°ì¤€ì´ ë„ˆë¬´ ê´€ëŒ€í•¨.
* **í•´ê²°**: í”„ë¡¬í”„íŠ¸ì— **"ëƒ‰ì •í•œ IT ë©´ì ‘ê´€"** íŽ˜ë¥´ì†Œë‚˜ë¥¼ ë¶€ì—¬í•˜ê³ , ì—°ì°¨ ë¯¸ë‹¬ ì‹œ ê°ì  ì¡°ê±´ì„ ëª…ì‹œí•˜ì—¬ 60~85ì  ì‚¬ì´ì˜ í˜„ì‹¤ì ì¸ ì ìˆ˜ê°€ ë‚˜ì˜¤ë„ë¡ ì¡°ì •.





[ Data Ingestion ]       [ Data Lake / Warehouse ]       [ AI Serving Layer ]
      (Bronze)                  (Silver / Gold)               (RAG Engine)

  +--------------+          +------------------+          +------------------+
  | Job Source   |          |  AWS S3 (Raw)    |          |  FastAPI Server  |
  | (Wanted API) |          |  [Bronze Layer]  |          |  (LangChain/RAG) |
  +--------------+          +------------------+          +------------------+
         |                          ^                             ^
      (Consume)                     |                             |
         v                   (Scheduled Batch)             (Vector Search)
  +--------------+          +------------------+          +------------------+
  | Kafka Cluster| --------> |  Spark Cluster   | -------> |    Qdrant DB     |
  | (Streaming)  |          |  (Clean/Embed)   |          |   [Gold Layer]   |
  +--------------+          +------------------+          +------------------+
                                    |                             ^
                             (Save Standard)                      |
                                    v                             |
                            +------------------+                  |
                            |    Postgres      | -----------------+
                            |  [Silver Layer]  |
                            +------------------+

[ Orchestration: Apache Airflow (Docker-out-of-Docker) ]