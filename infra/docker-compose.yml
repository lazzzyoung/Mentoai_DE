version: "3.8"

services:
  
  zookeeper:
    image: zookeeper:latest
    container_name: mentoai-zookeeper
    ports:
      - "2181:2181"
    platform: linux/arm64

  
  kafka:
    image: apache/kafka:latest
    container_name: mentoai-kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_NODE_ID=1
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@localhost:9093
      - KAFKA_LISTENERS=EXTERNAL://:9092,INTERNAL://:29092,CONTROLLER://:9093
      - KAFKA_ADVERTISED_LISTENERS=EXTERNAL://localhost:9092,INTERNAL://kafka:29092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=EXTERNAL:PLAINTEXT,INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL
    platform: linux/arm64

  
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: mentoai-kafka-ui
    ports:
      - "8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=mentoai-cluster
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:29092
    depends_on:
      - kafka
    platform: linux/arm64

  
  postgres:
    image: postgres:13
    container_name: mentoai-postgres
    platform: linux/arm64
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=mentoai
    ports:
      - "5432:5432"

  
  spark-master:
    image: apache/spark-py:latest
    container_name: spark-master
    user: root  
    ports:
      - "7077:7077"   
      - "8082:8080"
    env_file:
      - ../.env
    environment:
      - SPARK_MODE=master
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - DB_URL=jdbc:postgresql://postgres:5432/mentoai
    volumes:
      - ..:/opt/airflow  
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    platform: linux/arm64

  spark-worker:
    image: apache/spark-py:latest
    container_name: spark-worker
    user: root
    env_file:
      - ../.env
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - DB_URL=jdbc:postgresql://postgres:5432/mentoai
    volumes:
      - ..:/opt/airflow
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    platform: linux/arm64
  
  airflow-webserver:
    image: apache/airflow:2.8.1
    container_name: airflow-webserver
    platform: linux/arm64
    command: webserver
    ports:
      - "8081:8080"
    environment:
      - AIRFLOW__WEBSERVER__SECRET_KEY=my_very_secure_secret_key_12345
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
    volumes:
      - ..:/opt/airflow
    depends_on:
      - postgres


  airflow-scheduler:
    image: apache/airflow:2.8.1
    container_name: airflow-scheduler
    platform: linux/arm64
    command: scheduler
    env_file:
      - ../.env
    environment:
      - AIRFLOW__WEBSERVER__SECRET_KEY=my_very_secure_secret_key_12345
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092 # 명시적으로 덮어쓸 수도 있음
    volumes:
      - ..:/opt/airflow

    depends_on:
      - postgres
      - airflow-webserver


  airflow-init:
    image: apache/airflow:2.8.1
    container_name: airflow-init
    platform: linux/arm64
    depends_on:
      - postgres
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
    command: >
      bash -c "airflow db init && 
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com"