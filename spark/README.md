âš¡ MentoAI: AI-Based Career Data Pipeline
ì±„ìš© ê³µê³  ë°ì´í„°ë¥¼ ìˆ˜ì§‘(Kafka), ì €ì¥(S3), ì •ì œ(PostgreSQL), ê·¸ë¦¬ê³  ë²¡í„°í™”(Qdrant)í•˜ì—¬ ì‚¬ìš©ì ë§ì¶¤í˜• ì»¤ë¦¬ì–´ íë ˆì´ì…˜ì„ ì œê³µí•˜ëŠ” ì—”ë“œíˆ¬ì—”ë“œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.

ì‘ì„±ì: ê°•íƒœì˜ (ì»´í“¨í„°ê³µí•™ê³¼ / 2022110200)

ê¸°ìˆ  ìŠ¤íƒ: Python, Apache Spark, Kafka, Airflow, PostgreSQL, Qdrant, AWS S3

ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°
Plaintext
MENTOAI-DE/
â”œâ”€â”€ kafka/              # ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ (Producer)
â”œâ”€â”€ spark/              # ë°ì´í„° ì²˜ë¦¬ ëª¨ë“ˆ (Medallion Architecture)
â”‚   â”œâ”€â”€ utils/          # Spark Session, Reader/Writer, Cleaner
â”‚   â”œâ”€â”€ job_ingest_bronze.py  # Job 1: Kafka -> S3
â”‚   â”œâ”€â”€ job_process_silver.py # Job 2: S3 -> Postgres
â”‚   â””â”€â”€ job_upsert_gold.py    # Job 3: Postgres -> Qdrant (ì˜ˆì •)
â”œâ”€â”€ infra/              # Docker Compose ë° ì¸í”„ë¼ ì„¤ì •
â”œâ”€â”€ .env                # í™˜ê²½ ë³€ìˆ˜ (AWS Key, DB ì ‘ì† ì •ë³´ ë“±)
â””â”€â”€ requirements.txt    # í†µí•© íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì •
ğŸš€ ì‹œì‘ ê°€ì´ë“œ
1. Spark ì»¨í…Œì´ë„ˆ ì ‘ì† ë° í™˜ê²½ ì„¤ì •
Docker Composeê°€ ì‹¤í–‰ ì¤‘ì¸ ìƒíƒœì—ì„œ Spark Master ì»¨í…Œì´ë„ˆì— ì ‘ì†í•˜ì—¬ ì˜ì¡´ì„± ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

Bash
# 1. Spark Master ì»¨í…Œì´ë„ˆ ì ‘ì†
docker exec -it spark-master bash

# 2. ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ í†µí•© requirements.txt ì„¤ì¹˜
# (ë³¼ë¥¨ ë§ˆìš´íŠ¸ ì„¤ì •ì— ë”°ë¼ /opt/airflow ê²½ë¡œì— ìœ„ì¹˜í•¨)
pip install -r /opt/airflow/requirements.txt
2. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤
ëª¨ë“  Spark Jobì€ spark-master ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì˜ /opt/airflow/spark ê²½ë¡œì—ì„œ spark-submitìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.

## Step 1: Bronze Layer (Raw ë°ì´í„° ì ì¬)
Kafkaì˜ ë°ì´í„°ë¥¼ S3ì— ì›ë³¸ ê·¸ëŒ€ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

Bash
/opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262 \
  /opt/airflow/spark/job_ingest_bronze.py

## Step 2: Silver Layer (ë°ì´í„° ì •ì œ ë° RDBMS ì ì¬)
S3ì˜ ë°ì´í„°ë¥¼ ì½ì–´ êµ¬ì¡°í™”í•œ ë’¤ PostgreSQLì— ì €ì¥í•©ë‹ˆë‹¤.

Bash
/opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262,org.postgresql:postgresql:42.6.0 \
  job_process_silver.py

## Step 3: Gold Layer (ì„ë² ë”© ë° ì¸ë±ì‹±, Vector DB ì ì¬)
Postgres DBì˜ ë°ì´í„°ë¥¼ ì½ì–´ Embedding & Indexing í›„ Vector DB(Qdrant) ì— ì ì¬í•©ë‹ˆë‹¤.

Bash
/opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --packages org.postgresql:postgresql:42.6.0 \
  job_upsert_gold.py

ğŸ›  ì£¼ìš” ì²˜ë¦¬ ë¡œì§
ì¤‘ë³µ ì œê±°: id í•„ë“œë¥¼ ê¸°ì¤€ìœ¼ë¡œ dropDuplicatesë¥¼ ìˆ˜í–‰í•˜ì—¬ ë°ì´í„° ì¼ê´€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.

ê²°ì¸¡ì¹˜ ì²˜ë¦¬: ë§ˆê°ì¼(due_time) ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° "ìƒì‹œì±„ìš©"ìœ¼ë¡œ ê¸°ë³¸ê°’ì„ í• ë‹¹í•©ë‹ˆë‹¤.

ìœ ë‹ˆì½”ë“œ ë³µêµ¬: JSON íŒŒì‹± ê³¼ì •ì—ì„œ ì´ìŠ¤ì¼€ì´í”„ëœ í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ì›ë˜ ë¬¸ìë¡œ ë³µì›í•©ë‹ˆë‹¤.

ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬: ë°ì´í„° ìœ ì‹¤ ë° ì¤‘ë³µ ì²˜ë¦¬ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ S3 ë‚´ì— ì „ìš© checkpoints/ ê²½ë¡œë¥¼ ìš´ì˜í•©ë‹ˆë‹¤.

âš ï¸ ì£¼ì˜ ì‚¬í•­
S3 ì²´í¬í¬ì¸íŠ¸ ì´ˆê¸°í™”: ë¡œì§(ìŠ¤í‚¤ë§ˆ)ì´ ë³€ê²½ëœ ê²½ìš°, ë°˜ë“œì‹œ S3ì˜ checkpoints/ í´ë”ë¥¼ ì‚­ì œí•œ í›„ ì¬ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

DB ìŠ¤í‚¤ë§ˆ: ìƒˆë¡œìš´ í•„ë“œ(location, is_newbie ë“±) ì¶”ê°€ ì‹œ PostgreSQLì— í•´ë‹¹ ì»¬ëŸ¼ì´ ìƒì„±ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤.

ë„¤íŠ¸ì›Œí¬: Docker ì»¨í…Œì´ë„ˆ ê°„ í†µì‹  ì‹œ localhostê°€ ì•„ë‹Œ ì„œë¹„ìŠ¤ ì´ë¦„(kafka, postgres, qdrant)ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.